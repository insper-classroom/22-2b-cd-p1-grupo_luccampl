{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Insper - Ciência dos Dados - Projeto 1\n",
    "\n",
    "# Obtenção das notícias\n",
    "\n",
    "Utilize este notebook para **baixar notícias** sobre algum assunto de seu interesse.\n",
    "\n",
    "As notícias serão automaticamente baixadas do site https://www.istoedinheiro.com.br/ utilizando a **seção** de notícias e **quantidade de páginas**\n",
    "\n",
    "Será gerado um arquivo `dados.xlsx` contendo as informações disponíveis para o projeto.\n",
    "\n",
    "## Preparação do ambiente no jupyter\n",
    "\n",
    "Vamos importar algumas bibliotecas e definir algumas funções úteis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import time\n",
    "import random\n",
    "from math import floor\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_result(content, page=1, secao=''):\n",
    "    \n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "    lista_tag_noticia = soup.find_all('article', class_='thumb')\n",
    "\n",
    "    lista_titulo = []\n",
    "    lista_desc = []\n",
    "    lista_data = []\n",
    "    lista_page = []\n",
    "\n",
    "    for i in range(0, len(lista_tag_noticia)):\n",
    "\n",
    "        tag_noticia = lista_tag_noticia[i]\n",
    "\n",
    "        titulo = tag_noticia.find('h3').text\n",
    "        titulo = titulo.replace('\\n', '')\n",
    "        lista_titulo.append(titulo)\n",
    "\n",
    "        descricao = tag_noticia.find('p').text\n",
    "        lista_desc.append(descricao)\n",
    "\n",
    "        data_hora = tag_noticia.find('time', class_='c-data').text\n",
    "        lista_data.append(data_hora)\n",
    "\n",
    "    df = pd.DataFrame({'Categoria': secao,\n",
    "                       'Titulo': lista_titulo,\n",
    "                       'Descrição': lista_desc,\n",
    "                       'Data': lista_data,\n",
    "                       'Pagina': page,\n",
    "                       'Target': None\n",
    "                      })\n",
    "    return df\n",
    "    \n",
    "def get_content(url):\n",
    "    headers = ({'User-Agent':\n",
    "            'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "    resposta = requests.get(url=url, headers=headers, timeout=30)\n",
    "    resposta.encoding = 'utf-8'\n",
    "    return resposta.text\n",
    "\n",
    "def get_news_page(secao, page):\n",
    "    url = f'https://www.istoedinheiro.com.br/categoria/{secao}/page/{page}/'\n",
    "    content = get_content(url)\n",
    "    df_res = parse_result(content, page, secao)\n",
    "    return df_res\n",
    "\n",
    "def get_df_news(assuntos_noticias, n_pages=3):  \n",
    "    print('\\nProgresso:')\n",
    "    max_not = n_pages*len(assuntos_noticias)\n",
    "    prog_bar = IntProgress(min=0, max=max_not)\n",
    "    display(prog_bar)\n",
    "\n",
    "    for page in range(1, n_pages+1):\n",
    "        for i, assunto in enumerate(assuntos_noticias):\n",
    "            df_aux = get_news_page(assunto, page)\n",
    "            \n",
    "            if page==1 and i==0:\n",
    "                df = df_aux\n",
    "            else:\n",
    "                df = pd.concat([df, df_aux], ignore_index=True)\n",
    "        \n",
    "            prog_bar.value += 1\n",
    "            sec_sleep = random.randint(2, 5)\n",
    "            time.sleep(sec_sleep)\n",
    "            \n",
    "    return df\n",
    "\n",
    "def get_news(assuntos_noticias, n_pages=3, perc_train=0.6):\n",
    "       \n",
    "    if not os.path.isfile('../../data/dados.xlsx'):\n",
    "        \n",
    "        print(f'Ok! Vou baixar notícias sobre nas seções {assuntos_noticias} no IstoEDinheiro.com.br!')\n",
    "        print('\\nAguarde... Este processo pode demorar alguns minutos!')\n",
    "        \n",
    "        df = get_df_news(assuntos_noticias, n_pages)\n",
    "        df = df.sample(frac=1.0)\n",
    "    \n",
    "        writer = pd.ExcelWriter('../../data/dados.xlsx')\n",
    "        \n",
    "        n_real = len(df)\n",
    "        n_treino = floor(n_real * perc_train)\n",
    "\n",
    "        dft = df.iloc[:n_treino]\n",
    "        dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "        dfc = df.iloc[n_treino:]\n",
    "        dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "        writer.save()\n",
    "        \n",
    "        print('Processo finalizado!')\n",
    "        print('\\nGeramos um arquivo chamado dados.xlsx na pasta data, confira!')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        raise Exception('Arquivo dados.xlsx já existe na pasta data! Apague o arquivo caso queira gerar novamente!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defina as Categorias\n",
    "\n",
    "Defina na próxima célula uma lista com as seções ou categorias do site **IstoEDinheiro** nas quais gostaria de encontrar notícias para o Projeto 1.\n",
    "\n",
    "Precisa ser uma categoria válida no site\n",
    "\n",
    "Exemplos:\n",
    "- estilo\n",
    "- economia\n",
    "- black-friday\n",
    "- negocios\n",
    "- mercado-digital\n",
    "- financas\n",
    "- giro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quer pesquisar notícias em quais seções do site?!\n",
    "# Ex: assuntos_noticias = ['estilo', 'economia']\n",
    "assuntos_noticias = ['tecnologia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(assuntos_noticias) == 0:\n",
    "    raise Exception('Defina pelo menos um assunto na lista assuntos_noticias!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defina a quantidade de páginas\n",
    "\n",
    "Execute a próxima célula e escolha a quantidade de páginas a serem baixadas.\n",
    "\n",
    "**ATENÇÃO**: cada página contém múltiplas notícias!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Altere aqui!\n",
    "# Defina quantas páginas de cada seção quer recuperar.\n",
    "qtde_paginas = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if qtde_paginas <= 0:\n",
    "    raise Exception('Você precisa definir a quantidade de páginas!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtenção das notícias\n",
    "\n",
    "Execute a próxima célula. Ela irá construir uma base de dados de notícias sobre o seu assunto de interesse!\n",
    "\n",
    "Este processo poderá demorar alguns minutos. Quando ele finalizar, será gerado um arquivo `dados.xlsx` com as notícias!\n",
    "\n",
    "Pontos de atenção:\n",
    "- Confira se a quantidade de notícias encontradas foi suficiente (conforme enunciado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok! Vou baixar notícias sobre nas seções ['tecnologia'] no IstoEDinheiro.com.br!\n",
      "\n",
      "Aguarde... Este processo pode demorar alguns minutos!\n",
      "\n",
      "Progresso:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cbd99723c00419da65b29fc6652a966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=750)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processo finalizado!\n",
      "\n",
      "Geramos um arquivo chamado dados.xlsx na pasta data, confira!\n"
     ]
    }
   ],
   "source": [
    "get_news(assuntos_noticias, n_pages=qtde_paginas, perc_train=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
